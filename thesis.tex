%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% EPFL report package, main thesis file Goal: provide formatting for theses and
% project reports Author: Mathias Payer <mathias.payer@epfl.ch>
%
% This work may be distributed and/or modified under the conditions of the
% LaTeX Project Public License, either version 1.3 of this license or (at your
% option) any later version.  The latest version of this license is in
% http://www.latex-project.org/lppl.txt
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


% useful links:
% REPICA: https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8454360
%         good state of the art overview, both ARM64 and arm32
%         1. do not use symbolization, but relative address correction
%         2. Detect jump tables and global pointers, but not fix them
%         3. Overhead is exactly the same as retrowrite


%\pdfcompresslevel=0 \pdfobjcompresslevel=0

\documentclass[a4paper,11pt,oneside]{report}
\usepackage[MScThesis,lablogo]{EPFLreport} \usepackage{xspace}
\usepackage{xcolor} 
\usepackage{soul}
\usepackage{hyperref}
\usepackage{listings} 
\usepackage{caption}
\usepackage{booktabs}
\usepackage{siunitx}
\usepackage{bm}

\definecolor{lgray}{rgb}{0.92,0.92,0.92}

\lstset{ %
  language=[x86masm]Assembler,    
  framexleftmargin=5pt,
  framexrightmargin=5pt,
  %framesep=100pt,
  basicstyle=\linespread{1}\ttfamily\large,      
  numbers=left,                  
  numberstyle=\small\color{gray},  
  numbersep=15pt,
  stepnumber=1,                   
  backgroundcolor=\color{lgray},  
  tabsize=4,                      
  captionpos=b,                   
  breaklines=true,               
  breakatwhitespace=false,      
  title=\lstname,              
  keywordstyle=\color{blue},     
  commentstyle=\color{dkgreen}, 
  stringstyle=\color{mauve},   
  escapeinside={\%*}{*)},     
  morekeywords={adrp, add, adr, ldrb, br, uxtw, sxtb, b.eq, ldr, movz}
}


\title{Arm Wrestling: efficient binary rewriting on ARM}
\author{Luca Di Bartolomeo} \adviser{Prof. Mathias Payer (EPFL)}
\supervisor{Prof. Kenny Paterson (ETH)}

\linespread{1.5} 
\newcommand{\sysname}{RetroWrite\xspace}

%\newcommand{\todo}[1]{\colorbox{cyan}{\parbox{0.9\textwidth}{#1}}}
%\newcommand{\todo}[1]{%
	%\begingroup 
	%\sethlcolor{cyan}%
	%\hl{TODO: #1}%
	%\endgroup
%}
%\newcommand{\mat}[1]{%
	%\begingroup 
	%\sethlcolor{red}%
	%\hl{MAT: #1}%
	%\endgroup
%}

\DeclareRobustCommand{\todo}[1]{{\sethlcolor{cyan}\hl{TODO: #1}}}
\DeclareRobustCommand{\mat}[1]{{\sethlcolor{red}\hl{MAT: #1}}}



\dedication{ 
\begin{raggedleft}
	No matter where you go, everyone is connected.\\
	--- Serial Experiments Lain\\
\end{raggedleft} 
\vspace{4cm} 
\begin{center}
	Dedicated to my parents, my sister Sara, my dear Giulia, to my friends back 
	in Rome and to my roommates Matteo and Filippo who all inspired me and kept 
	up with my constant complaining. Thanks!
\end{center} 
}

\acknowledgments{
	I would like to thank my advisor, Prof. Mathias Payer, for his support,
	guidance, and for trusting me by assigning me this inspiring project.  I
	admire him a lot and I wish all the best for him, and in particular I hope
	that I can work on many other projects with him.
	
	I would also like to thank his research group, HexHive, as I always found
	myself very welcome there, even if I could visit them only once a week.  
	Those have been six very happy months in which I learned quite a lot of 
	things, and I have to thank prof. Prof. Payer and his doctorate students 
	and researches for it. I wish them all to have a very succesfull career, 
	and I hope we can continue to work together in the future!
	
	Special thanks goes to my family and my friends in Rome. Their support was
	always available, and it has always been a huge pleasure to visit them once
	in a while in Italy. I also need to thank my S.O. Giulia, I felt she was
	always behind my back, keeping a good check on my mental sanity during the
	worst times of the outbreak. My roommates too, Matteo and Filippo, deserve
	a mention here, as their patience and their rubber duck debugging skills
	proved to be fundamental during some nasty debugging sessions.

	Finally, I would also like to mention my CTF team, Flagbot, that made me 
	spend so many weekends without going out but ultimately lead me to meet so 
	many new interesting people, and the teams I had played with occasionally, 
	namely polyglots and TRX. Thanks!
}

\begin{document}
\maketitle
\makededication
\makeacks


\begin{abstract}

	%While there were good recent attempts, 
	%limiting our computing to only open-source software
	%is particularly hard, and especially on the mobile phone market even the
	%most determined users are often forced to use closed-source libraries or
	%modules.  Those often run at privileges higher than we might want (e.g.,
	%manufacturer specific kernel modules \cite{androidclosed}), and are also
	%hard to audit for vulnerabilities. 

	Closed source programs are particularly hard to audit for vulnerabilities.
	Moreover, it is often the case that modern security measures and
	mitigations are available only as compiler passes that require possession
	of the source code. Even if there were good recent attempts
	\footnote{\url{https://www.pine64.org/pinephone/}}
	\footnote{\url{https://system76.com/}}
	\footnote{\url{https://puri.sm/products/}}
	at completely avoiding usage or closed source libraries of modules that run
	at privileges higher than we might want (e.g., manufacturer specific kernel
	modules \cite{androidclosed})
	in practice it is almost impossible to restrict our computing to
	exclusively open source and audited software.  It is then of paramount
	importance that we find new ways of securing software without source code.



	Many existing tools were developed to improve the auditability of closed
	source programs, especially aimed at helping the fuzzing process, with
	approaches such as implementing AddressSanitizer (a compiler pass only
	available with the source code) through dynamic instrumentation. However,  
	even state-of-the-art dynamic instrumentation engines incur in prohibitive 
	runtime overhead (10x and more). Static rewriters are increasing in popularity, 
	but they are mostly targeted towards the \texttt{x86} architecture.

	We would like to show that symbolization for ARM binaries 
	is a viable alternative to existing approaches, that has less flexibility 
	(only works on C, position independent binaries) but has
	negligible overhead compared to compiled source code. We present 
	RetroWrite-ARM, a \emph{zero-overhead} static binary rewriter for \texttt{aarch64}
	executables that solves key challenges such as pointer construction
	detection and jump table instrumentation, based on 
	the \sysname project.

	Our proof of work implementation of a memory sanitizer instrumentation
	pass has the same functionality of the source-based counterpart, and our
	benchmarks show that it is \todo{xx\%} faster than Valgrind's \texttt{memcheck}.

	%which implements the symbolization engine and the memory
	%sanitization instrumentation. 

	%While \sysname is not the only binary rewriter for \texttt{x86}, there are 
	%very few that are aimed at the ARM64 architecture. In particular, most of 
	%them resort to lifting to an intermediate IR (achieving more flexibility 
	%but losing fine-grained control over the instrumented instructions) or use 
	%approaches like trampolines which make the whole problem much easier but 
	%also introduce a noticeable overhead.
	%\todo{add a fourth paragraph conclusion to this abstract, like "our proof of work 
	%implementation of retrowrite is xx\% faster than QEMU and etc..."}


\end{abstract}


\maketoc

%%%%%%%%%%%%%%%%%%%%%%
\chapter{Introduction}
%%%%%%%%%%%%%%%%%%%%%%
%The introduction is a longer writeup that gently eases the reader into your
%thesis~\cite{dinesh20oakland}. Use the first paragraph to discuss the setting.
%In the second paragraph you can introduce the main challenge that you see.
%The third paragraph lists why related work is insufficient.
%The fourth and fifth paragraphs discuss your approach and why it is needed.
%The sixth paragraph will introduce your thesis statement. Think how you can
%distill the essence of your thesis into a single sentence.
%The seventh paragraph will highlight some of your results
%The eights paragraph discusses your core contribution.
%This section is usually 3-5 pages.

Mobile environments are ubiquitous but often lack security updates, for
example, on Android over 60\% of devices are outdated by at least two
years~\cite{android}. Security testing in mobile environments is extremely
challenging as vendors often release components as binary-only, i.e., without
accompanying source code.  Binaries cannot be readily evaluated by security
analysts, resulting in potentially undiscovered vulnerabilities in this
binary-only modules, which often run with high privileges and are exposed to
the network.  Binary rewriting allows analysts to work with binary-only modules
but existing solutions are faced with severe disadvantages of either high
overhead for dynamic rewriting and limited rewriting capabilities for static
solutions.

While there is no shortage of static rewriters targeted towards the
\texttt{x86} architecture, only a few support \texttt{ARM}. One of the reasons
behind this is that \texttt{ARM} CPUs were not popular until very recently;
furthermore \texttt{ARM} poses very different challenges in the realm of static
rewriting. Trampolines and other kinds of instrumentation are made much easier
by the fixed-size instruction set, as problems such as overwriting instructions
shorter than a jump are not present.  However, that does not hold true for all
instrumentation techniques: the modern \emph{symbolization} approach for
instrumentation that \sysname and other recent binary rewriters adopted becomes
particularly harder. 

Symbolization is the process of substituting pointers and references in the 
executable with assembly labels, in order to permit arbitrary insertion of 
instructions without breaking the original functionality of a binary. On 
\texttt{ARM} there is the non-trivial problem of the detection of pointer 
constructions, as since a whole pointer does not fit into a single instructions 
it is very common to build pointers at runtime through multiple memory and 
arithmetic instructions. Furthermore, after detecting the construction of a 
pointer, it is not clear how the construction could be cleanly substituted with 
an assembly label. 

Another problem specific of the \texttt{ARM} architecture that affects binary 
rewriting is caused by how jump tables are stored in memory. Contrary to 
\texttt{x86}, jump tables are stored as offsets from the base case, and are 
often \emph{compressed}, i.e., each case takes much less space than the size of 
a pointer (usually one or two bytes is enough). Detecting them is hard, as they 
look like random bytes when inspecting memory (and code will access them 
through pointer construction); symbolizing them is even harder, as inserting 
instrumentation could break the compression in memory.

State-of-the-art binary rewriters for \texttt{ARM} use different approaches 
such as trampolines (which do not incur in the problems stated above, as 
trampolines only require minimal fixes in the binary to work) or lifting to an 
intermediate IR.  However, they introduce a non-negligible overhead, as any 
instrumentation location added now has two additional jumps that need to be 
executed and that frequently invalidate the code cache. 

In this thesis we present and discuss how we overcame those challenges to make 
\sysname support \texttt{aarch64} binaries. Through heavy use of 
backward-slicing static analysis we are able to recover pointer construction 
patterns; we also avoid breaking jump tables by compressing them in-place even 
more (if necessary). We also implemented an example instrumentation pass, 
\emph{AddressSanitizer}, which shows the ease and efficiency of writing 
instrumentation with the symbolization approach. 

We will show that our binary rewriter incurs in very low overhead through 
standard CPU benchmarks used by the scientific community to evaluate rewriters.  
We will also show that our implementation scales well to COTS binaries, as the 
benchmarks include large programs such as \texttt{gcc} and \texttt{perl}.  
Finally, we also evaluate the performance of our implementation of 
AddressSanitizer, showing that it is competitive with its source-based 
counterpart, adding only 30\% additional overhead on top of it. 

Our core contribution consists in the development of the first zero-overhead 
\texttt{aarch64} static binary symbolizer that scales to large COTS binaries, 
with key insights in detecting and symbolizing pointer construction mechanisms 
and compressed jump tables, and an efficient instrumentation pass that 
retrofits \texttt{aarch64} binaries with ASan.



%%%%%%%%%%%%%%%%%%%%
\chapter{Background}
%%%%%%%%%%%%%%%%%%%%
%The background section introduces the necessary background to understand your
%work. This is not necessarily related work but technologies and dependencies
%that must be resolved to understand your design and implementation.
%This section is usually 3-5 pages.

Here we will provide a summary of the basic notions required to understand the 
underlying concepts behind \sysname and the problems we faced while porting 
it to the ARM architecture. 

\section{Binary Rewriting}
\emph{Binary rewriting} describes the alteration of a compiled program without 
having the source code at hand in such a way that the binary under 
investigation keeps the same functionality. The applications of binary 
rewriting are multiple and can be summarized as follows:
\begin{itemize}
	\item \textbf{Cross ISA binary translation}: A binary translator is a special
		software that mimics the behaviour of a device while executing on a
		different device. Emulators use binary rewriting to translate system
		calls, instructions, memory access and all the other execution
		primitives from one processor architecture to another.  An example of
		this would be QEMU \cite{qemu}.

	\item \textbf{Optimization}: In high performance computing domains, having 
		a way to patch subtle things like cache misses or timing anomalies in 
		very long running tasks without the need to restart the whole program 
		is of special interest. In such situations, binary rewriting is a 
		solution for run-time patching, as it is done by DynInst \cite{dyninst} 
		or Frida \footnote{\url{https://frida.re/}}

	\item \textbf{Profiling}: Having an in-depth look during the execution of 
		a binary by inserting profiling or tracing instructions in the middle 
		of its code can prove to be particularly useful in many applications, 
		like catching memory leaks (e.g., Valgrind \cite{valgrind}), coverage 
		information for fuzzing (e.g., AFL-QEMU \cite{afl}) and more.

	\item \textbf{Hardening}: The absence of source code, combined with no 
		vendor support, or deprecated build tools, could make the use of binary 
		rewriting necessary to introduce security measures such as the 
		insertion of stack canaries (e.g., Stackguard \cite{stackguard}) or 
		memory sanitization (e.g., \sysname \cite{dinesh20oakland}).
	
\end{itemize}

Instrumenting a binary is not an easy task, as it is often said that binaries 
have a \emph{rigid} structure, because moving any data or code, or inserting 
instructions, will break all the references inside said binary. Thus, a binary 
rewriter must make sure that all the pointers and control flow broken by the 
inserted instrumentation are corrected.

In the next section we will analyze the difference between the two different 
approaches that can be taken for binary rewriting, namely \emph{dynamic} and 
\emph{static} instrumentation.




\section{Dynamic and Static Instrumentation}

\subsection{Dynamic instrumentation} Dynamic rewriters modify and instrument
the code of the target binary during runtime. Usually, the target binary is
executed in a controlled environment side by side with the rewriter engine,
which patches instructions and fixes references on the go. Sometimes the
rewriter engine leverages the operating system's primitives to control the
execution of the target, like using the \texttt{ptrace} system call on Linux,
but there are notable cases in which the rewriter engine comes with their own
instrumentation runtime (e.g., Dynamo~\cite{dynamo}) or implement a full
featured virtual machine (e.g., STRATA~\cite{strata}).

The big advantage of dynamic rewriters is the additional information that is 
only available at run time, like the path that the execution has taken.  
Furthermore, dynamic rewriters can avoid analyzing the whole binary at once, as 
they can just focus on the part that is being currently executed, making them 
scalable to arbitrarily large programs.

However, the additional runtime information comes at a high performance cost: 
running the rewriter engine alongside the target binary is expensive, and 
furthermore the frequent context switches the CPU must do to execute both make 
the situation even worse. The total overhead for an instrumentation pass like 
memory sanitization for a state-of-the-art dynamic rewriter like Valgrind are 
in the order of 10x~\cite{dinesh20oakland} the overhead introduced by 
source-level memory sanitization.

\subsection{Static instrumentation}
Static rewriters process the target binary \emph{before} execution, and produce 
as output a new binary with all the required instrumentation already there.  
This approach nets a big advantage in the fact that, except in some rare cases, 
very low overhead is introduced, and execution speed is comparable to 
compile-time instrumentation. Furthermore, static rewriters are able to add 
complex instrumentation that is computationally expensive to introduce, as 
since it is done statically, it won't introduce unnecessary delays at runtime.

Without runtime information, to correctly perform instrumentation static 
rewriters need to rely on complex analysis, which is inherently imprecise and 
often falls back on heuristics. It turns out that the common disadvantage of 
static rewriters is that they do not scale well on bigger binaries, or binaries 
that do not follow standard patterns. In fact, virtually no static rewriter 
supports packed binaries or self-modifying code. Moreover, many rewriters 
struggle with binaries produced by deprecated compilers or with aggressive 
optimization flags. 

More recent static rewriters such as Ramblr~\cite{ramblr}, 
Uroboros~\cite{uroboros}, and \sysname rely on \emph{symbolization} (sometimes 
also called \emph{reassemblable assembly}), which work around the rigid 
structure of binaries by substituting hard coded references with assembly 
labels, that are more flexible and can be parsed by any generic off-the-shelf 
assembler.  \sysname's approach is particularly interesting in the fact that it 
avoid heuristics to differentiate between scalars and references by focusing on 
position-independent executables (PIE). 



\section{Examples of code instrumentation}
In this section we will go into more detail on our particular use-case of 
instrumentation, \emph{fuzzing}, and explain what is the basis of 
AdressSanitizer, the instrumentation pass we implemented in the ARM port of 
\sysname. 

\subsection{Fuzzing}
Automatic vulnerability discovery techniques are getting a lot of traction 
lately, mostly because software is getting ever more complex and large, and 
manual analysis and auditing does not scale very well. Fuzzing is certainly one 
of the most interesting automatic vulnerability discovery techniques.  It 
relies on the pseudo-random generation of test cases to give as input to a 
target binary, trying to find a specific input that makes the binary get into 
an invalid or undefined state, as it is a good indicator of a possibly 
exploitable vulnerability. This technique got even more popular after the 
release of \texttt{AFL}~\cite{afl}, a fuzzer that relies on coverage  
information to generate new test cases to maximize the amount of instructions 
tested by each new input, and \texttt{Honggfuzz}~\cite{honggfuzz}, a modern 
fuzzer used to efficiently test APIs thanks to its innovative \emph{persistent 
fuzzing} feature.

Most state-of-the-art fuzzers rely on instrumentation to improve vulnerability 
discovery, as it makes the fuzzing process much more efficient. A fuzzer that 
focuses on binaries for which no instrumentation is available is commonly 
called a \emph{black-box fuzzer}. 

\subsection{ASan}
\emph{AddressSanitizer}, or ASan in short, is one of the most common static 
memory sanitization checks that can be added to a binary through a compiler 
pass, implemented in both the \texttt{clang} and \texttt{gcc} family of 
compilers. This compiler pass helps finding bugs by actively checking for 
memory corruptions, hooking calls to libc's  \texttt{free} and \texttt{malloc} 
functions. ASan is not only used by developers to debug their code before 
releasing to production, but it is also extensively used by fuzzers, as ASan 
will detect a memory violation as soon as it happens, letting the fuzzer know 
earlier and with more reliability when a bug was found. 

ASan works by introducing a new region of memory called \emph{shadow memory}, 
with a size of exactly 1/8 of the whole virtual memory available to a process.
By keeping track of each call to \texttt{malloc} and \texttt{free}, ASan stores 
in the shadow memory a compressed layout of the valid memory in the original 
virtual space, and sets up \emph{red zones} to highlight invalid or freed 
memory, that trigger a security violation as soon as they are accessed. Despite 
its non-negligible overhead (Around 73\% on average~\cite{asanoverhead}), ASan 
is widely used thanks to the absence of false-positives, and for its usefulness 
in detecting memory corruption vulnerabilities which are still extremely 
popular in C/C++ codebases.





\section{The ARM architecture}
We will provide a short summary of what are the main differences between 
\texttt{x86} and ARM, with particular focus on the ones that proved to be 
source of non trivial problems during the porting of \sysname.
\begin{itemize}
	\item \emph{Fixed-size instruction set}: Contrary to \texttt{x86}, the ARM 
		instructions are all of the same size, fixed to the value of 4 bytes.  
		While this is not a problem in itself, it means that a pointer cannot 
		fit into a single instruction. To store a pointer in a register in ARM, 
		there are two main options: the first is using a region of data where 
		the pointer is hard-coded at compile time, called a \emph{literal 
		pool}; the second one is building the pointer in a multi-stage fashion 
		by using arithmetic operations.  While the first one is easier, it is 
		also less performant, and compilers will always resort to the second 
		when possible. This makes very hard recovering information about global 
		variable accesses.
	\item \emph{Jump table compression}: On \texttt{x86}, jump tables are 
		stored as list of pointers in a data section (usually 
		\texttt{.rodata}), with one pointer for each case of the jump table.  
		Instead, on ARM, jump tables are stored as offsets from the base case.  
		This is because the compiler will try to compress the jump table, and 
		in most cases a single byte is enough to indicate the offset from the 
		base case to for each case of the jump table. This leads to problems 
		for static rewriting: first of all jump tables are harder to detect, as 
		on \texttt{x86} scanning the data sections for arrays of valid 
		instruction pointers was a quite reliable way of detecting jump tables, 
		while on ARM they are indistinguishable from random bytes; secondly 
		inserting too much instrumentation between cases of the same jump table 
		could lead to the offset not fitting into a single byte anymore, and 
		breaking the whole jump table structure in memory.  Finally, extracting 
		the number of cases of a jump table is quite harder in ARM, since it is 
		impossible to scan cases until an invalid pointer is found, as like 
		stated before, jump table entries in ARM are indistinguishable from 
		random bytes.
	\item \emph{Discontinuities in immediates}: Some ARM instructions, like 
		\texttt{ADD}, support having immediates as one of the operands.  
		However, they do not accept a classical range of immediates like in 
		\texttt{x86}, but instead a specific set of values that may not be 
		continuous.  For example the \texttt{ADD} instruction can use only 
		immediates that can be expressed with a value of 8 bits scaled by a 
		\texttt{ROR} with a
		4 bits value.
	\item \emph{Alignment issues}: The stack pointer register \texttt{sp} must 
		always be aligned to 16 bytes. Failing to do so will trigger a 
		\texttt{SIGBUS} error and crash the application.
	\item \emph{No push/pop}: There are no instructions in \texttt{aarch64} 
		equivalent to the \texttt{x86} push/pop. Instead, a push is performed 
		by storing a register on the stack and manually decreasing the stack 
		pointer, like \verb|str x0, [sp, #-16]!|. Similarly, a pop can be 
		performed like this \verb|ldr x0, [sp], #16|.

	\item \emph{Multiple register stores/loads}: The \texttt{aarch64} 
		architecture supports saving and loading two registers at once from 
		memory with instructions such as \texttt{stp} and \texttt{ldp}. They 
		are very often used by programmers and compilers thanks to the 
		performance gain.

	\item \emph{Peak performance vs energy efficiency}: While \texttt{x86} is 
		aimed towards maximising performance and speed, one of the main 
		objectives of the design of the \texttt{ARM} architecture is maximising 
		energy efficiency. This is the reason behind the simplicity of the 
		instruction set, as the CPU can be smaller and less complex compared to 
		\texttt{x86} --- and, ultimately, less transistors translate to less 
		power consumed. 

	\item \emph{Not enough mature tools}: The popularity of ARM CPUs is still 
		relatively new and the tooling is not mature enough, as in fact we 
		found bugs in both the disassembler we chose to use 
		(Capstone~\cite{capstone}) and the debugger (GDB)
\end{itemize}


%%%%%%%%%%%%%%%%
\chapter{Design}
%%%%%%%%%%%%%%%%
%Introduce and discuss the design decisions that you made during this project.
%Highlight why individual decisions are important and/or necessary. Discuss
%how the design fits together.
%This section is usually 5-10 pages.


We will now go over the goals that we designed \sysname according to, explain
which were the key issues that we had to face due to the quirks of the ARM
architecture, and the solutions we adopted to overcome those problems both in
the \emph{symbolization} and in the \emph{instrumentation} sides of \sysname.


\section{Goals}

Our goal is to develop a zero-overhead binary translator for \texttt{aarch64} 
executables that enables powerful translation and overcomes challenges spawned 
by the ARM ISA.\@ It should also support COTS software and scale well to large 
binaries. Finally, its implementation should be modular in such a way as to 
avoid limiting any kind of instrumentation.


\section{System architecture}

\begin{figure}[h]
\includegraphics[width=15cm]{symbolizer.jpg}
\centering
\caption{Overview of the structure of \sysname}
\end{figure}

\sysname is divided into two main components: the symbolizer and the 
instrumentation.  The symbolizer takes care of loading and analyzing a binary, 
but its main job is substituting every reference in the target with assembly 
labels, plus some minor tasks to keep the original functionality of the binary 
intact. 
Listing \ref{diffass}  shows the output of the symbolization process on a
small example assembly snippet.

One or more instrumentation passes can be enabled to apply 
transformations to the resulting binary. For now, only a single pass is 
implemented (BASan), but many more can be easily added.



\begin{figure}[h]
\begin{minipage}{.45\textwidth}

\begin{lstlisting}
0x400: adr  x0, 0xab0000
0x404: cmp  x1, 20
0x408: b.eq 4
0x40c: ret
0x410: ret
\end{lstlisting}


\end{minipage}\hfill
\begin{minipage}{.45\textwidth}

\begin{lstlisting}
.LC400: adr  x0, .LCab0000
.LC404: cmp  x1, 20
.LC408: b.eq .LC410
.LC40c: ret
.LC410: ret
\end{lstlisting}

\end{minipage}
\captionof{lstlisting}{Assembly in the original binary (left), and after symbolization (right)}
\label{diffass}
\end{figure}



\section{Key Issues}
The outstanding challenges of statically analyzing and instrumenting ARM 
binaries can be summarized as follows:

\begin{itemize}
	\item Detecting and fixing pointer constructions.
	\item Detecting and symbolizing jump tables.
	\item Supporting extensive instrumentation by enlarging jump tables.  
\end{itemize}

In the following pages we will get into detail for each one of those issues, 
and explain the reasoning behind our solution.

\subsection{Pointer construction}
The Aarch64 instruction set is defined as \emph{fixed size}, because every 
instruction is large exactly 4 bytes. This makes the CPU design simpler,
helps keeping memory always aligned, and permits the CPU to fetch multiple 
instructions at once, since decoding is not necessary to determine instruction 
boundaries. However, despite the many advantages of this characteristic, there 
are some drawbacks too, including not being able to store a pointer in a single 
instruction (as pointers have a size of 8 bytes). The Aarch64 ISA provides two 
main solutions to this problem. 

The first one consists in storing the pointers in a special read-only region of 
memory, called a \emph{literal pool}, and then load those pointers into a 
registers using the special construct \texttt{ldr <reg>, =pointer}, a 
pseudo-instruction that the assembler will translate with the correct memory 
address once \texttt{pointer} has been stored in a literal pool.  Since all 
\emph{ldr} instructions are PC-relative, and since there are 21 bits available 
to store the offset from the PC, the assembler will store \emph{pointer} in a 
literal pool which is in the $\pm$ 1MB range of the \texttt{ldr} instruction.  
While this is a simple and straightforward approach, very useful in the case of 
hand-written assembly, this requires an additional memory access that may 
impact performance in the long run. Furthermore, the assembly will fail if it 
is not possible to store a literal pool in the given range, such as in the case 
of a function larger than 2MB.\@ In that case, it is up to the programmer to 
find a suitable spot for the literal pool, by manually specifying its location 
with the \texttt{.ltorg} assembly directive. It is often recommended to store 
literal pools directly after non-conditional jumps to avoid executing 
them~\cite{literalpools}.

The second solution is to build pointers using multiple instructions and basic 
arithmetic primitives. Aarch64 provides instructions such as \texttt{adrp 
<reg>, pointer}, which loads the base page of a pointer into a register. It is 
a PC-relative instruction, and targets pointers in the $\pm$ 4GB range.  In 
other words, the \texttt{adrp} instruction can point only to memory locations 
that are 4KB aligned. Usually the instruction can be followed by an 
\texttt{add}, a \texttt{sub} or an offset-based load such as \texttt{ldr 
<register>, [<base\_page>, offset]}. This second way, while more contrived and 
certainly harder to read, is faster than the first one as it does not require a 
memory access, and also often benefits from custom hardware optimizations (such 
as in the Cortex A72, one of the most common ARM 
CPUs~\cite{pointeroptimizations}). 

\subsubsection{The global variable problem}
For the reasons stated above, compilers generally use the second option, 
preferring performance over assembly readability. Having each pointer value 
separated in two different instructions makes the static analysis of a binary 
substantially harder. Furthermore, compiler optimizations frequently exacerbate 
the problem, by reusing parts of some pointer values to build new ones, or 
reordering instructions around in such a way that a pointer can be built on two 
instructions which are kilobytes away from each other. In some extreme cases, 
by enabling the \texttt{-O3} optimizations, we found instances of pointers 
built on two instructions that were on different functions, due to the compiler 
optimizing a macro in the C source code. 

An important factor to note is that this behaviours happens exclusively when 
accessing \emph{global variables}, since all code pointers and local variables 
are reachable through a single pc-relative instruction. 

In the symbolization process (that will be explained in detail later), we need 
to know the value of every pointer used in the program, in order to correct it 
when we will add instrumentation later on. Thus we are required to develop an 
analysis technique that lets us recover the value of every single global 
pointer used in the binary. We will now shortly describe the ideas behind the 
solution we implemented.

\subsubsection{Our solution for the global variable problem}

At first, some basic static analysis is performed on the binary, in order to 
recover functions, control flow, basic blocks and disassembly of the 
\texttt{.text} section. After this, we scan the disassembly for each possible 
instance of pointer building in the binary. After analyzing common compiler 
patterns, we found out that the \texttt{adrp} instruction (which loads the base 
page address of a pointer) is an indicator of a possible start of a pointer 
building process. 

After collecting all the possible instances of pointer building, the next step 
is to find out the final pointer value of each one. This turned out to be an 
extremely difficult task, as we soon found out that there are infinitely many 
ways of how a pointer can be built. We implemented a pattern-matching solution 
at first, trying to detect common compiler patterns for pointer building; while 
we correctly found out the value of the vast majority of pointers, a single 
mistake could make the binary crash, and our solution was not working on 
binaries of large sizes, as we inevitably failed to parse at least one or two 
edge-cases.

We later shifted to a different approach: instead of trying to find exact value 
of a pointer by pattern matching, we take the set of all possible values a 
pointer could have and exclude wrong values until possible. Over 90\% of the 
times, this approach leaves only a single value. The rest of the times, only 
two or three values remain, for which we use the old pattern-matching solution 
to understand which of those is the correct one. 

This final solution scales really well, as proved by the fact that we rewrote 
very large binaries and successfully ran them through long benchmarks. For more 
details on how the exclusion algorithm works, see the next chapter, 
Implementation.  


\subsection{Jump table target recovery}
There is a big difference in how jump tables in ARM are implemented compared to 
\texttt{x86}. In fact, in \texttt{x86}, a jump table is represented through a 
list of code pointers in the \texttt{.rodata} section. The assembly generated 
by the compiler will simply load the pointer from the list indexed by the 
number of the case that is going to be executed. 

On ARM, things are different: jump tables are stored as a list of 
\emph{offsets} from the base case (case number 0) in memory. The compiler 
generates assembly that fetches the correct offset based on the case number 
from the list in memory, adds the offset to the base case, and jumps to the 
resulting value. Listing~\ref{lst:jmptbl} shows an example of jump table access 
in \texttt{aarch64}. The first two instructions build a global pointer to where 
the jump table is stored in memory. In line 3 the offset to the corresponding 
case is loaded into register \texttt{w1}, and then later added to the base case 
\texttt{x0} on line 5. 


\begin{lstlisting}[float,floatplacement=H,label={lst:jmptbl},caption={Example of a jump table in \texttt{aarch64}}]
adrp x0, <jump_table_page_address>
add x0, x0, <jump_table_page_offset>
ldrb w1, [x0, w1, uxtw]
adr x0, <base case address>
add x0, x0, w1, sxtb 2
br x0
\end{lstlisting}

Furthermore, jump tables in \texttt{aarch64} are complicated by the fact that 
they are often \emph{compressed} in memory. Since they store offsets, not 
pointers, and commonly jump table cases are very close to the base case, 
compilers usually avoid using the full 8 bytes of memory for each case (which 
would be normal in \texttt{x86}), but will use less if possible. For instance, 
if all offsets are less than 256, the compiler will use a single byte in memory 
to store each case.  

\subsubsection{Detection of jump tables}
The first problem we had to face was the discovery of jump tables. While they 
have a very distinct pattern (a load from memory, followed by some arithmetic, 
and then an indirect jump), many other constructs share similar patterns (like 
using a callback in a struct). We found out that a reliable way of detecting 
them is by backward-slicing every time the disassembler encountered an indirect 
jump, and then verifying if the value of the register used for the indirect 
jump could be represented with an expression which could be resolved statically 
and matched a very defined pattern (load 1/2/4 bytes from memory, load a base 
address, add the offset and then jump to the result). 

To represent the value of a register as an expression, we developed a simple
pseudo-emulation engine that steps backwards from a given instruction, 
following control flow and building step by step the resulting expression, 
similar to what a dumbed-down symbolic executor would output. The 
pseudo-emulation engine is limited, supports circa 20 instructions, as 
emulating ARM was out of the scope of the project and we only needed it for 
jump table detection. A detailed explanation of how it works can be found in 
the next chapter.

\subsubsection{Detection of jump tables size}
Another problem that quickly arose from the peculiarities of ARM jump tables is 
that it is much harder to estimate the number of cases that a jump table 
supports, compared to \texttt{x86}. In fact, in \texttt{x86}, simple heuristics 
such as scanning memory for contiguous sections of valid instruction pointers 
until an invalid one is found can go a long way. However, as stated before, in 
ARM jump tables are indistinguishable from random bytes, so it is impossible to 
use heuristics to understand the bounds of a particular jump table in memory.

We found that backward slicing is again a robust solution here too. After 
detecting a jump table, we can identify the instruction that takes care of 
loading the offset from memory, and from there we mark the register that holds 
the value of the number of the case that is going to be executed.  
Backward-slicing until a comparison operation is performed on the marked 
register, bounding the number of cases to an absolute number, turned out to be 
a very reliable solution.  

\subsection{Enlarging jump tables}
Another problem spawned from how jump tables are represented in ARM comes up 
when instrumenting a function that contains a jump table. In fact, it is very 
likely that adding too much instrumentation inside a single case could 
\emph{overflow} one of the offsets that stored its distance from the base case.
Especially when maximum compression is used and offsets are stored in a single 
byte, it is very common to overflow multiple of them even with light 
instrumentation. 

This was one of the harder problems to fix, and we considered the following 
solutions:
\begin{itemize}
	\item Expand the jump table in memory. Enlarge the \texttt{.rodata} section 
		and move everything to make space in memory for the expanded jump 
		table. While possible, this would have been be a drastic change that 
		was not scalable or easily implemented.
	\item Create a new jump table in a new section, and patch the pointer 
		building code at the start of the jump table access code. While this 
		was the easiest solution to implement, we discarded it because of the 
		additional space required and its poor scalability.
	\item Divide all the offsets by the same constant value. Normally, all 
		offsets of a jump table represent the distance between a case and the 
		base case expressed in bytes divided by 4. This is because each 
		instruction is 4 bytes long, and it would not make sense to point 
		inside an instruction. In fact, in Listing~\ref{lst:jmptbl}, line 5, we 
		can see how the offset is shifted by 2 to the left (so multiplied by 
		4). This is automatically done by the compiler. However, we can use the 
		same technique the compiler uses and store offsets divided by 8, 16 or 
		more, and changing how much the offset is shifted to the left before 
		being used, thus enabling us to store larger differences in a single 
		byte. 

		The trade-off with this approach is that offsets can no longer point to 
		a single instruction, but to a block of 2, 4 or more instructions, 
		depending on how much enlargement was needed. To make sure that each 
		offset points to the right instruction, some light \emph{nop-padding} 
		is applied between cases to make sure that alignment is correct every 
		time.
\end{itemize}

We ended up using the last solution, as even if it was slightly more complex to 
implement, it would help us keep the original memory layout of the binary, 
which is a very desirable property in binary rewriting. 

\subsection{Control Flow broken by instrumentation}
When adding substantial amount of instrumentation to a binary, some pc-relative 
branches can break, like the instruction \texttt{cbz}, which cannot jump to 
addresses farther than 1MB. 

In this cases we fix the relevant instruction by making them point to a some 
additional instrumentation containing a trampoline to the original target of 
the branch. 




\subsection{Instrumentation register saving}

We designed \sysname to support any kind of instrumentation, without 
sacrificing performance and functionality. We realized though that many 
different kinds of instrumentation require some intermediate calculations to be 
saved in registers. This was causing noticeable overhead in the 
instrumentation, as registers needed to be saved on the stack and restore in 
every instrumented location. 

To avoid this additional overhead, we implemented a static analysis of register 
usage for every function, with instruction-level granularity (i.e., the result 
of the analysis is the set of registers that can be freely used without saving 
them for every instruction inside a given function). The instrumentation can 
then use the set of free registers without worrying about hindering the 
original functionality of the binary. 



%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Implementation}
%%%%%%%%%%%%%%%%%%%%%%%%
%The implementation covers some of the implementation details of your project.
%This is not intended to be a low level description of every line of code that
%you wrote but covers the implementation aspects of the projects.

%This section is usually 3-5 pages.

In this chapter we cover the implementation of the rewriter, and of bASAN, the memory
sanitization instrumentation pass. We will also share details on the optimizations
we implemented to minimize instrumentation overhead.

\section{Symbolizer}


Symbolization requires detection of every single pointer and control flow
mechanism in the binary. In \texttt{aarch64}, this may prove to be harder than
it looks, as in fact pointer construction patterns are difficult to recover
and jump tables are not as friendly as they are in x86. 
In the following subsections we will go over each problem and explain our
approach to tackle it. 



\subsection{Pointer Construction}

\subsubsection{Detection and recovery of pointers}

Standard compilers (clang, gcc) that target \texttt{aarch64} use a common 
pattern for building pointers: an \texttt{adrp} instruction, loading the page 
of the destination address, and then either an \texttt{add} or similar arithmetic 
instruction to fix the offset inside the page, or a memory operation like 
\texttt{ldr} or \texttt{str} that include the offset inside the page 
(e.g., \texttt{ldr x0, [x1, 256]}).

We implemented two different approaches and combined them together to 
successfully recover pointers in \texttt{aarch64} binaries.
The first one is based on pattern matching. We first build a list of 
possible pointer building locations, enumerating all instances of the \texttt{adrp} 
instruction. Next, we tried to find all \texttt{add}, \texttt{ldr}, or 
\texttt{str} instructions (or their variants) that used the register that was 
partially built with the \texttt{adrp}, and tried to recover the original
pointer by emulating the arithmetics involved in those instructions.
This approach alone was not enough because of the following 
difficulties:

\begin{itemize}
	\item Multiple pointers built with the same \texttt{adrp}: As can be seen 
		in \autoref{pointers}, sometimes the same \texttt{adrp} page loading 
		instruction is used for multiple pointer constructions, sometimes very 
		far away from each other
	\item Moving base page register: another difficulty was that sometimes the 
		register used to store the base page changed in the middle of the 
		pointer construction, as can be seen in \autoref{pointers2}
	\item Base register stack saving: in very large functions, sometimes the 
		base registers were loaded at the start and saved on the stack, to be 
		later restored and used for pointer building. An example is present in 
		\autoref{pointers3}
\end{itemize}

\begin{lstlisting}[float,floatplacement=H,label=pointers,caption={Example of multiple pointers built from the same \texttt{adrp} instruction}]
adrp x0, 0xab0000
add  x1, x0, 256   // pointer 0xab100
ldr  x2, [x0, 512] // pointer 0xab200
add  x0, x0, 128   // pointer 0xab080
\end{lstlisting}
\begin{lstlisting}[float,floatplacement=H,label=pointers2,caption={Example of changing register during
pointer construction}]
adrp x0, 0xab0000
mov  x1, x0
add  x1, x1, 256   // pointer 0xab100
\end{lstlisting}
\begin{lstlisting}[float,floatplacement=H,label=pointers3,caption={Example of base page register stack
saving}]
adrp x0, 0xab0000
str  x0, [sp, -16!]
...
ldr  x3, [sp, 16!]
add  x3, x3, 512   // pointer 0xab200
\end{lstlisting}


We implemented a light data flow recovery algorithm
that statically analyzed the control flow and the stack usage of a given
function, following around the register used for the \texttt{adrp} and checking
for its usage, to address all the difficulties stated above. However, it is
particularly hard to support every single edge case, and missing a single
pointer symbolization is fatal and will cause a crash when the pointer is 
dereferenced (which sometimes happens a while after the pointer is built, 
and can be very time consuming to detect and debug). 
While this pattern matching approach alone worked with the vast majority of
pointer construction, it was insufficient to completely symbolize all pointers
and failed on large binaries. 

Our second approach took advantage of the fact that \sysname does not 
instrument data sections, and the vast majority of global variables point to
those. Instead of trying to parse the pointer building patterns, we try to
guess which section of the original binary an \texttt{adrp} could be pointing
to. Since the \texttt{adrp} loads a base page, and a page offset is added, the
sections that can be addressed by a single pointer constructions are those that
overlap the \texttt{adrp} address $\pm$ 1 KB.\@ Since all sections except
\texttt{.text} are not instrumented, if we are able to narrow down the possible
target of a pointer construction to a single section, we can symbolize the
pointer by just adjusting the starting 
\texttt{adrp} to correctly address the same symbolized section as in the 
original binary, since offsets used by \texttt{add} or \texttt{ldr} will stay 
the same.
For example, if we encounter the instruction \texttt{adrp x0, 0xab000} and the
only section close enough is the \texttt{.bss} that starts at address
\texttt{0xab256}, we can symbolize every pointer construction on \texttt{x0} by
changing the above \texttt{adrp} to \texttt{ldr x0, =(.bss - 256)}.

%\mat{Such a 'first we did x then we did y' is OK for a report. For a paper you
%would highlight your latest and final approach and mention only why other
%approaches do not work.}


This second approach is more stable, as it does not
incur in any of the problems stated above. However, it was not always
applicable, as especially in smaller binaries multiple sections could be in the
$\pm$ 1 KB range from the \texttt{adrp} destination address; in that case, we
used some simple data flow analysis to exclude as many sections as possible.
We found out that in around 99\% of cases we are able to use this \texttt{adrp}-adjusting
approach without needing to do any heuristics at all. In the case we are not able
to determine which single section the \texttt{adrp} is pointing to, we fall back
to the first pattern matching based approach. 


\subsection{Symbolization of pointers}

After detection of a pointer construction in the target binary, it is still not 
trivial how to symbolize a pointer. There are two solutions to this problem: 
using \emph{literal pools} and using pointer construction.

\subsubsection{Literal pools}

A literal pools is a special region of memory in a binary that stores absolute
addresses. It is widely used in \texttt{ARM} to overcome the challenge of not
being able to store a pointer in a single instruction. 

The \texttt{ARM} assembly specification~\cite{literalpoolsarm} states that the
assembler will store a pointer in a literal pool when using the following
construct: \texttt{ldr x0, =<pointer>}.  The \texttt{=<pointer>} part will be
assembled with a pc-relative load to the nearest literal pool that contains the
full pointer address.  The location of the literal pool must be manually
specified in assembly through the \texttt{.ltorg} directive. Usually, literal
pools are stored between functions in the \texttt{.text} sections. Since the
pc-relative load can only target addresses in the $\pm$ 1 MB range, literal
pools must be stored inside functions if they are larger than 2 MB. 

In our first implementation we used literal pools to symbolize pointers, but we 
detected noticeable overhead introduced even without instrumentation added. The runtime
of binaries without instrumentation was around 10\% compared to the original binaries. 
The reason behind the additional overhead is twofold: first, each pointer retrieved through
literal pools requires a memory access each time; secondly, literal pools occupy precious
space in the \texttt{.text} section causing more cache misses than necessary. 


\subsubsection{Pointer construction symbolization}

To avoid the overhead introduced by the usage of literal pools, we decided to
use pointer construction ourselves. The symbolization of a pointer construction
is composed of two parts: the symbolized \texttt{adrp} base page loading and
the symbolized \texttt{add} for the page offset. An example of such process can
be found in Listing \ref{lst:construction}. The \texttt{adrp} is symbolized by just
substituting its argument with the symbolized counter part.  The page offset part,
instead, is symbolized through a special assembler directive that evaluates to the
last 12 bits of the specified assembly label (and 12 bits are enough to specify
the offset inside a page). 

\begin{figure}[h]
\label{lst:construction}
\begin{minipage}{\textwidth}
\begin{lstlisting}[basicstyle=\ttfamily\small]
0x400: adrp  x0, 0xab000
0x404: add x0, x0, 256              // pointer to 0xab100
\end{lstlisting}
\end{minipage}

\begin{minipage}{\textwidth}
	\begin{lstlisting}[basicstyle=\ttfamily\small]
.LC400: adrp  x0, .LCab100          // base page 
.LC404: add x0, x0, :lo12:.LCab100  // page offset
\end{lstlisting}
\end{minipage}
	\captionof{lstlisting}{Example pointer construction in the original binary
	(above) and symbolized pointer construction (below)}
\end{figure}



\section{Jump Tables}

Switch statements in \texttt{ARM} binaries are stored as a table of offsets,
instead of absolute addresses like in \texttt{x86}. This makes symbolizing them
particularly tricky. First of all, detecting them is not easy. As can be seen
in Listing \ref{omgjmptbl}, they do not have a particular pattern in memory. In
this section we will go over what was our approach to finding them and how did
we symbolize them without breaking their functionality.



\begin{figure}[h]
\begin{minipage}{.50\textwidth}
\begin{lstlisting}[basicstyle=\ttfamily\small,numbers=none]
0x400: adrp x0, 0x8000
0x404: add x0, x0, 3
0x408: ldrb w1, [x0, w1, uxtw]
0x40c: adr x0, 0x418
0x410: add x0, x0, w1, sxtb 2
0x414: br x0
0x418: movz x0, 1   // case 0,1,2
0x41c: ret
0x420: movz x0, 10  // case 3
0x424: ret
0x428: movz x0, 100 // case 4
0x42c: ret
\end{lstlisting}
\end{minipage}\hfill
\begin{minipage}{.45\textwidth}
\begin{lstlisting}[basicstyle=\ttfamily\small,numbers=none]
0x8003: byte 0x0   // case 0
0x8004: byte 0x0   // case 1
0x8005: byte 0x0   // case 2
0x8006: byte 0x8   // case 3
0x8007: byte 0x10  // case 4
\end{lstlisting}
\end{minipage}
\captionof{lstlisting}{Left: code for a performing a switch. Register w1
	holds the case number that is going to be executed. The offset is loaded at
	\texttt{0x408}, which is added to the base case address (loaded at
	\texttt{0x40c}) and then jumped into (\texttt{0x414}). \\ Right:
	corresponding jump table in memory, with 5 cases each occupying a single
	byte in memory. Cases can be repeated, and are impossible to distinguish
	from other data in memory.}
\label{omgjmptbl}
\end{figure}




%\mat{Either be a bit more verbose/detailed about the problem or reference the
%section where you share the details.}

\subsection{Detection of jump tables}
Unlike \texttt{x86}, in \texttt{ARM} we cannot rely on heuristic such as looking for 
lists of valid instruction pointers in the \texttt{.rodata} section. 
However, compilers use very common patterns when using a jump table, as can be seen
in \autoref{jmptbl} and \autoref{omgjmptbl}. 
Our algorithm to detect a jump table pattern works in the following way:

\begin{itemize}
	\item Recover all control flow from every function, using standard CFG recovery techniques.
	\item Look for every location of an indirect jump, denoted by the \texttt{br} instruction. 
	\item Use backwards-slicing to find every possible path that could lead to
		that instruction, with a maximum path length of 50 instructions
	\item Reverse-emulate every path, and store every possible (symbolized)
		value that the register of the indirect call can have.
	\item If the value that the register can have is the same for every path,
		and corresponds to a jump table symbolic expression, then mark the
		\texttt{br} instruction as part of a jump table construct.
\end{itemize}

To reverse-emulate every path that leads to the indirect call, we implemented a
very limited \texttt{aarch64} symbolic instruction emulator. It supports around
20 ARM instructions (all those that are common in jump table constructs, plus
arithmetic instructions and a few memory-related ones).  A very simple example of the
output of this emulator can be found in \autoref{emulator} (jump table constructs are 
often more nuanced and interleaved with other instructions).

After we get the symbolic value of the indirect jump register, we compare it to
the standard jump table expression, which is the following:

\texttt{base\_case\_addr + (*(jump\_table\_base\_addr + (register\_case\_number * ?)) \textless\.\textless\  ?)} 

The symbol \texttt{?} is a wildcard for any (positive) integer value.
\texttt{base\_case\_addr} is the address of case 0 in the jump table.
\texttt{jump\_table\_base\_addr} is instead the address in memory of the jump
table offsets. Finally, \texttt{register\_case\_number} is a register with as
value the number of the case that is going to be executed. 


\begin{figure}[h]
\begin{lstlisting}[basicstyle=\ttfamily\small,numbers=none]
0x400: adrp x0, 0x8000
0x404: add x0, x0, 3
0x408: ldrb w1, [x0, w1, uxtw]
0x40c: adr x0, 0x418
0x410: add x0, x0, w1, sxtb 2
0x414: br x0
\end{lstlisting}
\begin{lstlisting}[basicstyle=\ttfamily\small,numbers=none]
Analyzing 0x414: br x0
x0 = x0
x0 = x0 + (w1 << 2)
x0 = 0x418 + (w1 << 2)
x0 = 0x418 + (*(x0 + w1*1) << 2)
x0 = 0x418 + (*(0x8003 + w1*1) << 2)
Result:
Base case: 0x418
Jump table addr: 0x8003
Case number reg: w1
Shift: 2
\end{lstlisting}
\captionof{lstlisting}{Above: example of a jump table pattern. Below: output of
our symbolic emulator. }
\label{emulator}
\end{figure}


\todo{Here I don't talk about detection of the number of cases of a jump table,
because I believe there is not much more to explain other than the part in the
design section. Is this OK?}


\subsection{Jump Table symbolization}

The symbolization of a jump table in memory is done using the assembler's 
support for simple arithmetic on assembly labels. Since on ARM a jump table
is no more than a sequence of offsets from a base instruction, we symbolize
that with differences between assembly label. An example of this can be seen
in \autoref{omgjmptbl}.

Since the offsets in the symbolized version are calculated with assembly labels,
any amount of code can be added between cases, and the assembler will make sure
that the jump table will work correctly. This is one of the cases where the benefits
of using symbolization as a rewriting technique really shines, as it gives us the 
freedom of inserting arbitrary instrumentation (even by hand) without having to worry
about correcting references.

However, there is a catch: adding \emph{too much} instrumentation could
overflow the value used to store the offset from the base case. In the example
in \autoref{omgjmptbl}, if there are more than 256 instructions between a case
and the base case, the offset will overflow as it is stored in a single byte.
In the next subsection we will cover how we actually support adding arbitrary
amount of instrumentation. 

\begin{figure}[h]
\begin{minipage}{.45\textwidth}
\begin{lstlisting}[basicstyle=\ttfamily\small,numbers=none]
0x8003: byte 0x0   // case 0
0x8004: byte 0x0   // case 1
0x8005: byte 0x0   // case 2
0x8006: byte 0x8   // case 3
0x8007: byte 0x10  // case 4
\end{lstlisting}
\end{minipage}\hfill
\begin{minipage}{.48\textwidth}
\begin{lstlisting}[basicstyle=\ttfamily\small,numbers=none]
0x8003: byte (.LC418 - .LC418) / 4
0x8004: byte (.LC418 - .LC418) / 4
0x8005: byte (.LC418 - .LC418) / 4
0x8006: byte (.LC420 - .LC418) / 4
0x8007: byte (.LC428 - .LC418) / 4
\end{lstlisting}
\end{minipage} 
\captionof{lstlisting}{Left: jump table as stored in memory as
found in the original binary. Right: symbolized jump table in the output of
\sysname.}
\label{omgjmptbl}
\end{figure}


\subsection{Jump Table enlargement}

When too much instrumentation between jump table cases is added, the value used
to store the offset from the base case can overflow. To address this, we
implemented support for using a larger divisor when storing assembly label
differences.  As an example, instead of storing \texttt{(LC418 - .LC410) / 4}
like in \autoref{omgjmptbl}, we can store \texttt{(.LC418 - .LC410) / 8} to fit
up to 512 instructions between \texttt{.LC418} and \texttt{.LC410}. The same reasoning
can be reapplied with higher powers of two. 

However, using a divisor higher than 4 means losing precision in the possible
addresses of the cases we want to represent. Since 4 bytes is the size of each
instruction, dividing by 4 means that every instruction can be targeted;
dividing by 8 means that only one every two instructions can be targeted. To
avoid losing precision over which instruction can be targeted or not, we insert
\texttt{nop} padding before each case of the jump table in the output assembly
in order to make every case targetable by an offset, with the amount of nops
depending on how high is the divisor (e.g., dividing by 8 means that each case
must by 8-byte aligned, so using up to 1 nop before each case; dividing by 16
means using up to 3 nops, and so on). Since the number of nops inserted depends on 
alignment, we leave this task to the assembler using the \texttt{.align} directives.

After changing the divisor, we also need to change the indirect jump calculations in the
binary's code to match the new shift value. Usually, the offset to be added is multiplied by
4 using an instruction like \texttt{add x0, x0, w1, sxtb 2} (which shifts left by 2), as
can be seen in \autoref{emulator}. We change the shift value according to how high we set
the dividend in the symbolized jump table (the \texttt{add} instruction support shifting left
up to 4, but we insert a standard \texttt{lsl} instruction before if it's higher than 4). 

An example of this can be found in Listing \ref{enlarged}.

\begin{figure}[h]
\begin{lstlisting}[basicstyle=\ttfamily\small,numbers=none]
.LC400: adrp x0, .LC8003
.LC404: add x0, x0, :lo12:.LC8003
.LC408: ldrb w1, [x0, w1, uxtw]
.LC40c: adr x0, .LC418
.LC410: add x0, x0, w1, sxtb 4
.LC414: br x0
.align 4
.LC418: movz x0, 1 // case 0,1,2
.LC41c: ret
.align 4
.LC420: movz x0, 10 // case 3
.LC424: ret
.align 4
.LC428: movz x0, 100 // case 4
.LC42c: ret
...
...
0x8003: byte (.LC418 - .LC418) / 16
0x8004: byte (.LC418 - .LC418) / 16
0x8005: byte (.LC418 - .LC418) / 16
0x8006: byte (.LC420 - .LC418) / 16
0x8007: byte (.LC428 - .LC418) / 16
\end{lstlisting}
\captionof{lstlisting}{Example of enlarged symbolized jump table. The shift value at \texttt{0x410} is increased from 2 to 4, and the divisor at \texttt{0x8003} is increased from 4 to 16. Before each case, an \texttt{.align 4} assembly directive is inserted, as each of them need to be aligned to 16 bytes.}
\label{enlarged}
\end{figure}


\section{Instrumentation (BASan)}
The ASan instrumentation was designed to be compatible with the 
AddressSanitizer libraries provided by Google, \texttt{libasan}. We carefully 
selected shadow memory offsets and sizes to match those included in 
\texttt{libasan}.  The library will hook on each call to \texttt{malloc} and 
\texttt{free}, writing in the shadow memory the available bytes that can be 
used. \sysname takes care of finding each access in memory and inserting 
instrumentation just before each access to check the relevant bytes of shadow 
memory and error out in case an overflow or other memory corruption was found.


\begin{lstlisting}[float,floatplacement=H,language=C,label={lst:asan},caption={ASan checking algorithm 
implemented in C}]
byte shadow_value = *(MemToShadow(address));
if (shadow_value) {
  if ((address & 7) + AccessSize - 1 >= shadow_value) {
	ReportError(address, AccessSize);
  }
}
\end{lstlisting}

Listing~\ref{lst:asan} shows the ASan checking algorithm in high level. To 
implement it as an instrumentation pass, we manually wrote assembly code that 
matched its functionality and could be adapted to both reads and stores.  
Different versions of ASan snippets were developed depending on the size of the 
store/load, to ensure maximum efficiency and avoid wasting calculations at 
runtime. An example of an instrumented instruction can be found in the listing 
below:

\todo{Add comparison between non-instrumented and instrumented 8-byte load (the 
simplest case)}

Unfortunately, the BASan instrumentation pass is not completely equivalent to 
its source based counterpart, in fact we can highlight the following 
differences:
\begin{itemize}
	\item Missing global variable bounds checking: without the source code, it 
		is impossible to distinguish boundaries between global variables in 
		data section. For this reason, checks on global variables are disabled.
	\item Missing stack variables bounds checking: similar to above, without 
		source code it is extremely hard to find boundaries between variables 
		on the stack.
	\item Number of instrumented locations: ASan used as a compiler pass is 
		able to prune the checking on a lot of memory accesses, since on many 
		instances the safeness of a memory access can be determined at 
		compile-time with the source code at hand. However, \sysname works only 
		on binaries and thus is forced to instrument all memory accesses.
\end{itemize}
Despite the following limitations, the BASan instrumentation pass provides the 
same core functionality of the original ASan compiler pass (memory sanitization 
on the heap), and with very little additional overhead.

\subsubsection{Optimization: register savings}.
The snippets of assembly used to implement ASan memory checking require some 
temporary register usage to store intermediate calculations, and thus require 
special precautions before inserting them in the middle of a binary. Our first 
approach was to save the values of each register we were planning to use on the 
stack, and then restore the old values as the last step of the instrumentation.  
However, we quickly realized that those frequent memory accesses were 
introducing noticeable overhead. 

We then switched to performing a static analysis of register usage on every 
function of the binary, in such a way that at any given instruction we know 
which registers can be freely used and which cannot be modified without 
hindering the correct execution of the binary. Then, when inserting the 
instrumentation, we modify the snippets in such a way that they will try to use 
as many `free' registers as possible, while saving the others on the stack.

Of particular note is the saving of the value of register \texttt{ncvz}, which 
holds the condition flags in \texttt{aarch64}. This register is always saved 
and restored at each instrumented location, as all ASan snippets contain a 
conditional branch for the error checking. 

\todo{If needed, put other optimizations here, like batching}


%%%%%%%%%%%%%%%%%%%%
\chapter{Evaluation}
%%%%%%%%%%%%%%%%%%%%
%In the evaluation you convince the reader that your design works as intended.
%approach without needing to do any heuristics at all. In the case we are not able
%Describe the evaluation setup, the designed experiments, and how the
%experiments showcase the individual points you want to prove.

%This section is usually 5-10 pages.


In this section we validate the claims that we made earlier by performing experiments.
We show that \sysname can symbolize and instrument ARM binaries with the performance of
source based instrumentation without compromises on its scalability.

\section{Setup and Hardware} 
We ran experiments on two machines:
\begin{itemize}
	\item A raspberry Pi 4B, with a Cortex A-72 (1.5GHz) CPU and 4GB of RAM
	\item An Atlas/A57 (2.4GHz) CPU with 64 GB of RAM
\end{itemize}

To benchmark the performance of rewritten binaries, we used the SPEC CPU 2017
benchmark suite~\cite{speccpu2017}.  We used only the C language benchmarks as
\sysname does not (yet) support the symbolization of C++ exceptions. The list of the
benchmarks can be seen in \autoref{tabularasa}.  All of the benchmarks were run on
the Atlas machine, while some of the benchmarks were not run on the raspberry because
4GB of RAM were not enough to avoid using swap memory, compromising the results
of the experiments. The Atlas machine was generously hosted by the CloudLab
pojerct~\cite{cloudlab} in their Utah data center. 

The benchmarks were compiled with the gcc compiler version 7.5.0 on a freshly
installed Ubuntu 18.04 operating system. The following command line flags were
used to compile the baseline benchmark binaries: \texttt{-O3
-fno-tree-loop-vectorize -fno-unsafe-math-optimizations -fgnu89-inline
-fno-strict-aliasing}, in addition to the flags to produce position independent
executables. To demonstrate the scalability of our approach, we will rewrite
binaries as large as the \texttt{gcc} benchmark (> 10MB).



We evaluate the performance of the symbolization engine by running the
benchmarks with the binaries of each benchmark rewritten by \sysname without
adding any kind of instrumentation. We then evaluate the performance of our
memory sanitization instrumentation pass by comparing it against its source
based equivalent (\texttt{-fsanitize=address} in the compiler flags), and
against the equivalent functionality implemented using a dynamic
instrumentation approach, by using Valgrind with the memory sanitization option
(\texttt{valgrind --tool=memcheck}).




\begin{table}
\centering
\begin{tabular}{lrr}
\toprule
	\textbf{Name} & \textbf{Size} & \textbf{Stripped size} \\
\toprule
	\texttt{cpugcc\_r   }              & 63 MB  & 10 MB  \\
	\texttt{perlbench\_r} \hspace{2em} & 11 MB  & 2.5 MB \\
	\texttt{imagick\_r  }              & 2.4 MB & 2.2 MB \\
	\texttt{x264\_r }                  & 687 KB & 645 KB \\
	\texttt{nab\_r      }              & 249 KB & 229 KB \\
	\texttt{xz\_r   }                  & 244 KB & 215 KB \\
	\texttt{mcf\_r      }              & 45 KB  & 38 KB  \\
	\texttt{lbm\_r      }              & 23 KB  & 18 KB  \\
\bottomrule
\end{tabular}
\caption{Name and size of the SPEC CPU2017 benchmarks written in C.}
\label{tabularasa}
\end{table}

\section{Symbolization performance}

As can be seen from \autoref{plot1} and \autoref{plot2}, the overhead of the
symbolization process is very small. Detailed results can be found in
\autoref{labellatabella}.  The average overhead is 0.76\%, in line with other
state of the art static rewriters~\cite{egalito}.  This kind of overhead is
probably due to unoptimal realignment of sections and code, as we produce
position independent assembly and we do not optimize for cache hits or anything
else, leaving this work entirely to the linker. Another important
factor for the overhead is that each pointer building instruction \texttt{adrp}
is symbolized with two instructions (an \texttt{adrp} followed by an
\texttt{add}); so for each global variable access the binary makes the CPU will
lose a clock cycle (probably less, as many ARM CPUs have hardware optimizations
for \texttt{adrp+add} sequences of instructions~\cite{pointeroptimizations}).

Interestingly, we managed to have such a low overhead only after the
elimination of literal pools to symbolize pointer building. When using literal
pools, the average overhead was 3.5\%, with the maximum value being at 10.7\%
for \texttt{perlbench} (see \autoref{slowpools} for more details) \todo{this is not true, as it was run on different machines. Re-run
everything on CloudLab}. 

A noticeable slowdown was introduced in \texttt{perlbench}; while a negative
one in the \texttt{mcf} benchmark. We consider the negative overhead in the
\texttt{mcf} benchmark to lie inside measurement error \todo{maybe calculate
standard deviation or error rates to give proof?}. We attribute the larger
overhead in \texttt{perlbench} to be caused by the vast amounts of global
variable accesses in the binary, as \texttt{perl} is an interpreted language
(\todo{do we require proof of this?  can we count the number of adrp executed
during the benchmark?}).


\section{Memory sanitization performance}

In this section we compare the overhead introduced by \sysname's memory
sanitization instrumentation and the overhead introduced by adding memory
sanitization during compilation (\texttt{-fsanitize=address}).  From
\autoref{labellatabella} we can see that source-based ASAN has a 84.04\%
overhead on average, but the overhead varies a lot between individual
benchmarks, depending on the amount of memory accesses. For example,
\texttt{perlbench}, running an interpreter, makes a high amount of memory loads
and stores that need to be individually checked by the address sanitizer each
time; in fact, the overhead is noticeably higher (173.84\%). The same holds
true for the \sysname's memory sanitization instrumentation (Binary ASAN in
\autoref{labellatabella}): the overhead is larger in programs that frequently
use memory. 

On average, binary ASAN is slower than source ASAN (109.73\% instead of 84.04\%
average overhead \todo{change basan average overhead, incorrect}). The reasons
behind the slowdown are the following:
\begin{itemize}
	\item Number of instrumented locations: Without source code available,
		\sysname cannot use certain types of analysis that the compilers use to 
		determine the safety of certain memory accesses. For this reason, \sysname
		instruments every single memory access, while source ASAN skips some of them.
	\item Assembly generation optimizations: \sysname is a relatively simple tool, 
		and instruments memory accesses with hand-written assembly snippets. While
		some optimizations were implemented (register savings, batching checks), they
		do not even come close to the number and complexity of optimizations passes that
		standard compilers use when generating machine code. 
\end{itemize}
Still, the slowdown with respect to source ASAN is very little compared to state of the art tools.
In fact, without source code, the only way of adding memory sanitization to a binary is through
dynamic instrumentation. We ran the benchmarks using a very famous dynamic instrumenter that implements
memory sanitization (Valgrind's \texttt{memcheck} tool~\cite{valgrind}), and plotted the runtimes in
\autoref{plot1} and \autoref{plot2}. The overhead introduced by dynamic instrumentation is around 10x the 
overhead of binary ASAN, depending on the amount of memory accesses of the benchmark. 

However, it needs to be said that our binary ASAN instrumentation has a few shortcomings. First of all,
stack variables access is not instrumented. Secondly, global variable accesses are not instrumented. Both
of those are caused by the fact that without source code, bounds determination is impossible for variables
in non-heap memory regions. 

\todo{Do we want to show how bad are trampolines? I could design a small experiment around that.}.


\todo{Do we want to talk about register savings and of how much time do they gain?}


\todo{Do we want to talk about cache misses? I already have scripts to measure them, I just need to 
run all the benchmarks all over again}


\begin{figure}[h]
\includegraphics[width=15cm]{cloudlab.pdf}
\centering
	\caption{Benchmark runtime on the Atlas machine. \todo{fix label names} \todo{update plot for new gcc results} }
\label{plot1}
\end{figure}

\begin{center}
\begin{figure}[h]
\includegraphics[width=\textwidth]{raspberry.pdf}
\centering
\caption{Benchmark runtime on the raspberry machine. \todo{fix label names} }
\label{plot2}
\end{figure}
\end{center}

\begin{table}
\centering
\begin{tabular}{lrrrr}
\toprule
	\textbf{Name} \hspace{4em} &\textbf{Symbolization only} & \textbf{Source ASAN} & \textbf{Binary ASAN} & \textbf{Valgrind} \\
\toprule

	\texttt{cpugcc\_r   } & 0.95\% &145.80\% & x.xx\% & 1729.20\% \\
	\texttt{perlbench\_r} & 2.91\% &173.84\% &260.10\% &3377.03\% \\
	\texttt{imagick\_r}   & 0.30\% & 71.53\% & 71.17\% &1578.53\% \\
	\texttt{nab\_r      } & 0.34\% & 28.57\% & 27.21\% &1110.82\% \\
	\texttt{xz\_r   }     & 0.44\% &105.79\% &144.76\% &1036.57\% \\
	\texttt{mcf\_r      } &-0.07\% & 40.77\% & 83.74\% & 390.94\% \\
	\texttt{lbm\_r      } & 0.59\% & 49.58\% & 97.31\% & 715.46\% \\
	\midrule
	\textbf{Average} & \textbf{0.76\%} & \textbf{84.04\%} & \textbf{109.73\%} & \textbf{1429.94\%} \\
\bottomrule
\end{tabular}
\caption{Overhead of \sysname without instrumentation and of \sysname with
BASAN instrumentation on SPEC CPU2017 on the Atlas machine compared to the original benchmark
and the original benchmarks compiled with source based ASAN.
\todo{update basan average, which is slightly wrong} } 
\label{labellatabella}
\end{table}


%\begin{table}
%\centering
%\sisetup{detect-weight=true}
%\sisetup{mode=text}
%\robustify\bfseries
	%\begin{tabular}{lS[table-format=1.2]S[table-format=3.2]}
%\toprule
%\textbf{Name} \hspace{4em} & {\textbf{Literal pools}} & {\parbox[c]{5cm}{\centering\textbf{Symbolized}\\ \textbf{pointer building}}} \\

%\toprule

	%\texttt{perlbench\_r} & 2.91\si{\percent} & 10.71\si{\percent} \\
	%\texttt{imagick\_r}   & 0.30\si{\percent} & 1.07\si{\percent} \\
	%\texttt{nab\_r      } & 0.34\si{\percent} & 0.00\si{\percent} \\
	%\texttt{xz\_r   }     & 0.44\si{\percent} & 2.39\si{\percent} \\
	%\texttt{mcf\_r      } & -0.07\si{\percent}& 2.42\si{\percent} \\
	%\texttt{lbm\_r      } & 0.59\si{\percent} & 0.91\si{\percent} \\
	%\midrule
	%\textbf{Average} & \bfseries 0.76\% & \bfseries 3.5\% \\
%\bottomrule
%\end{tabular}
%\caption{Overhead of \sysname without instrumentation comparing the recovery 
%of pointers by using literal pools and by using symbolized pointer building.
%\todo{The symbolized pointer building column needs to be redone from scratch} } 
%\label{slowpools}
%\end{table}

\begin{table}
\centering
\sisetup{detect-weight=true}
\sisetup{mode=text}
\robustify\bfseries
	\begin{tabular}{lS[table-format=1.2]S[table-format=3.2]}
\toprule
\textbf{Name} \hspace{4em} & {\textbf{Literal pools}} & {\parbox[c]{5cm}{\centering\textbf{Symbolized}\\ \textbf{pointer building}}} \\

\toprule

	\texttt{perlbench\_r} & 10.71\si{\percent} & 5.21 \si{\percent} \\
	\texttt{imagick\_r}   & 1.07 \si{\percent} & 0.33 \si{\percent} \\
	\texttt{nab\_r      } & 0.00 \si{\percent} & 0.00 \si{\percent} \\
	\texttt{xz\_r   }     & 2.39 \si{\percent} & 2.39 \si{\percent} \\
	\texttt{mcf\_r      } & 2.42 \si{\percent} & 1.20 \si{\percent} \\
	\texttt{lbm\_r      } & 0.91 \si{\percent} & 1.03 \si{\percent} \\
	\midrule
	\textbf{Average} & \bfseries 3.51\% & \bfseries 1.94\% \\
\bottomrule
\end{tabular}
\caption{Overhead of \sysname on the Raspberry without instrumentation comparing the recovery 
of pointers by using literal pools and by using symbolized pointer building.
\todo{The symbolized pointer building column needs to be redone, possibly on the CloudLab machine} } 
\label{slowpools}
\end{table}




%\hrule
%A. ScalabilityTable II shows a list of all successfully rewritten binariesand
%their sizes as part of the evaluation, demonstrating thescalability
%ofRetroWrite(RQ1). Prior work on reassem-bleable assembly uses coreutils to
%evaluate scalability to realworld software, which have a median size of 394KB
%and a

%maximum size of 1.3MB. As Table II shows, we evaluate on12 binaries that are
%larger than a megabyte, with a mediansize of 1.09MB (2.7xlarger) and maximum
%size of 12MB (9.2xlarger). Consequently, we are confident
%thatRetroWritecanrewrite arbitrary C binaries.B. Memory Checker  PerformanceWe
%evaluate the performance ofASan-retrowriteon the SPEC CPU2006 C benchmarks.
%Since the orig-inal benchmarks exhibit some memory safety violations,we applied
%patches provided in Googles Address Sani-tizer repository [53]. The Google
%patch blacklists instru-mentation of certain functions in perlbench,
%e.g.,char*movenoasan, as they cause violations. Our initial eval-uation
%ofASan-retrowritereported a use-after-free inthe above function, after which we
%manually removed ASanchecks from the same function for evaluation. All code
%wascompiled with options:-O2 -std=gnu89andgcc-5.4.0and flags to produce
%position-independent executables. Val-grind was configured to track the same
%set of features as ASan.Our evaluation indicates that on an average we are
%about300% better than Valgrind, and 65% slower than ASan.We present a detailed
%view of our results in Figure 3.The main reason for ASans low-overhead when
%comparedto other memory checkers is its highly optimized memorycheck
%instrumentation. Therefore, any additional overhead isclearly visible in
%long-running benchmarks. We identified thefollowing as causes for the overhead
%ofASan-REtrowrite when compared to ASan


%1)Instrumentation Locations.ASan-retrowritein-struments  more  locations  than
%source  ASan.  Thecompiler-based instrumentation removes some checks ifit can
%prove accesses are safe.2)Register Spills.As register allocation happens
%lateduring code generation, the compiler considers boththe original code and
%the instrumentation, therebygenerating better register allocation with fewer
%spills.ASan-retrowriteis limited to a conservative reg-ister liveness analysis
%and opportunistically uses deadregisters to reduce register spills, but cannot
%change theregister allocation scheme as a whole.3)Optimized Checks Placement.To
%reduce register pres-sure, or flag recomputations, source-based ASan is freeto
%move the memory check instrumentation (accordingto language semantics).
%However, our binary ASan can-not do this as hoisting checks is not always safe
%andneeds more principled compiler-like analysis.4)Loop Hoisting.Checking
%contiguous memory accessesin hot loops can be expensive. As a part of the
%op-timization pipeline, a compiler may choose to hoistsuch checks out of the
%loop and perform a singlecheck to reduce the overall overhead. Though
%possible,implementing such loop-hoisting mechanisms are a lotharder, mainly due
%to lack of abstractions such as loopsin the binary level.

%\hrule

%\section{Experiment overview}
%\todo{Explain our setup, the hardware we used, what we were measuring.}

%\todo{Talk a bit on also the difficulties caused by the nature of the 
%benchmarks, namely very long times (up to 48 hours, and probably more now that 
%I have CloudLab :D ), very high RAM usage, and so on.}

%\todo{(OPTIONAL) Talk a bit on how those difficulties were approached, with the 
%very strict collection of experiment metadata using Github CI and the telegram 
%bot.}

%\section{SPEC CPU}
%\todo{Explain how much do I hate the SPEC CPU benchmark, who developed it, the 
%crazy fact that it is the accepted state of the art method for benchmarking 
%single-core performance, how counter-intuitive their directory structure, 
%config files, and bash scripts are.  /s}

%\section{Results}
%\todo{Present  plots and tables, and a detailed explanation on each one.
%Make sure to respect the style of Mathias' previous papers/theses, to avoid 
%getting him unnecessarily angry}

%\todo{Compare it to state-of-the-art dynamic instrumentation (QEMU).}


%%%%%%%%%%%%%%%%%%%%%%
\chapter{Related Work}
%%%%%%%%%%%%%%%%%%%%%%

%The related work section covers closely related work. Here you can highlight
%the related work, how it solved the problem, and why it solved a different
%problem. Do not play down the importance of related work, all of these
%systems have been published and evaluated! Say what is different and how
%you overcome some of the weaknesses of related work by discussing the 
%trade-offs. Stay positive!
%This section is usually 3-5 pages.


% useful links:
% REPICA: https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8454360
%         good state of the art overview, both ARM64 and arm32
%         1. do not use symbolization, but relative address correction
%         2. Detect jump tables and global pointers, but not fix them
%         3. Overhead is exactly the same as retrowrite
% A SURVEY ON BINARY REWRITING: https://publications.sba-research.org/publications/201906%20-%20GMerzdovnik%20-%20From%20hack%20to%20elaborate%20technique.pdf

{

\setlength{\parindent}{0cm}

\todo{This section now has only list of related work I would like to talk 
about, will be expanded later}


\todo{Complain about egalito}



\textbf{Dynamic rewriters in general}:\\
First, the good ol' ones: \texttt{PIN}~\cite{pin}, 
\texttt{Valgrind}~\cite{valgrind} and \texttt{DynInst}~\cite{dyninst}.

More recently, \texttt{Multiverse}~\cite{multiverse}, \texttt{Frida} and 
\texttt{DynamorIO} are interesting examples.

\texttt{QASAN}~\cite{qasan} is similar to \sysname's BASan, much slower but 
also much more portable (works on any binary supported by QEMU)



\textbf{Static rewriters that use lifting to IR}:\\
\texttt{McSema}~\cite{mcsema} is a great example of LLVM IR lifting approach, 
also particularly nice as it supports C++ exceptions

\textbf{Static rewriters that use trampolines}:\\
\texttt{E9patch}~\cite{e9patch} uses only trampolines, no need to recover 
control flow, but also noticeable overhead

%\todo{Also say that trampolines are especially effective on ARM because every 
%instruction is always 4 bytes, so you don't need to worry about overwriting 
%instructions shorter than a jmp like in x86}

\textbf{Static rewriters that use symbolization}:\\
\texttt{Uroboros}~\cite{uroboros} and \texttt{Ramblr}~\cite{ramblr} are the 
first reassemblable assembly approaches (symbolization), 
\sysname~\cite{dinesh20oakland} (x86 version)

\textbf{Static rewriters aimed at ARM binaries}:\\
\texttt{Repica}~\cite{repica} is probably the most recent addition to binary 
rewriters aimed at ARM binaries.  

\todo{Maybe add Bistro?}~\cite{bistro}

For more check out recent surveys on the area of binary rewriting~\cite{binaryrewritingsurvey}

}

%%%%%%%%%%%%%%%%%%%%%
\chapter{Future Work}
%%%%%%%%%%%%%%%%%%%%%

{

\setlength{\parindent}{0cm}
\hangindent=0.7cm \textbf{Support for more source languages}: For now, 
\sysname supports only binaries compiled from the C language, both for the 
\texttt{x86} and the ARM implementation. The easiest addition would be to add 
support for C++ by expanding the analysis capabilities of \sysname to support 
exception tables too, but many more languages could be supported in the future. 

\hangindent=0.7cm \textbf{Support for kernel space binaries}: Right now the ARM 
port of \sysname supports only userspace binaries, contrary to the 
\texttt{x86} version that supports linux kernel modules too. The kernel version 
of \sysname\_ARM would prove to be particularly interesting as it would open 
new ways to efficiently fuzz Android kernel modules.

\hangindent=0.7cm \textbf{Support for more executable formats/operating 
systems}: The current implementation of the \sysname tool is aimed only 
towards ELF files, but adding support for MACH-O and PE binaries should not 
require too much effort. This would also be interesting as Windows and MacOS 
present way more closed-source modules compared to Linux.

\hangindent=0.7cm \textbf{More instrumentation passes}: While right now we 
implemented only the AddressSanitizer instrumentation in the ARM port of
\sysname, the design of \sysname is modular and adding new instrumentation 
passes or new mitigations should be easy. To name a few, the interesting ones would be:
\begin{itemize}
	\item Shadow stack (return address protection)
	\item Control flow authentication using ARM pointer authentication 
		(hardware-assisted)
	\item Coverage-guidance for fuzzing
\end{itemize}

}

%%%%%%%%%%%%%%%%%%%%
\chapter{Conclusion}
%%%%%%%%%%%%%%%%%%%%

%In the conclusion you repeat the main result and finalize the discussion of
%your project. Mention the core results and why as well as how your system
%advances the status quo.


In summary, we develop the ARM architecture implementation of the \sysname 
project, a scalable static rewriter for linux C binaries.  \sysname enables 
targeted application of static instrumentation where no source code is 
available, such as proprietary binaries, inline assembly, or code generated by 
a deprecated compiler.  We also present an example instrumentation pass on top 
of the symbolization engine, AddressSanitizer, particularly useful for fuzzing 
purposes. We present new solutions to problems arising from the peculiarities 
of the ARM architecture such as the fixed-size instruction set, global variable 
accesses and jump table instrumentation. We show that the total overhead of the 
symbolization and the instrumentation pass are competitive with source based 
AddressSanitizer.  Our work shows that \sysname's original approach is not 
limited to the \texttt{x86} architecture, but can be applied to the ARM 
architecture and more.



\cleardoublepage
\phantomsection

\addcontentsline{toc}{chapter}{Bibliography}
\printbibliography

% Appendices are optional
% \appendix
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \chapter{How to make a transmogrifier}
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% In case you ever need an (optional) appendix.
%

\end{document}
